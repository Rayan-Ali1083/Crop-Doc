{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4jrngLm6GijY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_hub as hub\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hwQQzeZMB76"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sabryqthLpfk"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=256\n",
        "BATCH_SIZE=32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoAqf9BQLCOK"
      },
      "outputs": [],
      "source": [
        "def import_dataset(path, IMG_SIZE=256,BATCH_SIZE=32):\n",
        "  dataset=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "      # path,\n",
        "      shuffle=True,\n",
        "      image_size=(IMG_SIZE,IMG_SIZE),\n",
        "      batch_size=BATCH_SIZE\n",
        "  )\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK4N40Qn9RzO"
      },
      "outputs": [],
      "source": [
        "dataset=import_dataset(path,IMG_SIZE,BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBbGCSfQ43Kh"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIpRpOUaMQe9"
      },
      "outputs": [],
      "source": [
        "class_names=dataset.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7tNSd5m1wk1"
      },
      "outputs": [],
      "source": [
        "for image, label in dataset.table(1):\n",
        "  print(image.shape)\n",
        "  print(label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o42fbLcI1wnU"
      },
      "outputs": [],
      "source": [
        "def visualize_data(dataset):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for image, label in dataset.table(1):\n",
        "    for i in range(10):\n",
        "      ax=plt.subplot(2,5,i+1)\n",
        "      plt.imshow(image[i].numpy().astype(\"uint8\"))\n",
        "      plt.title(class_names[label[i]])\n",
        "      plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJwUq8c_8Isb"
      },
      "outputs": [],
      "source": [
        "visualize_data(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtdRlZkF49eF"
      },
      "source": [
        "# Split the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60su3HE44wCS"
      },
      "outputs": [],
      "source": [
        "def train_test_split(dataset,train_split=0.8 , test_split=0.1, validation_split=0.1 ,shuffle=True,shuffle_size=10000):\n",
        "  dataset_size=len(dataset)\n",
        "  if shuffle:\n",
        "    datatset=dataset.shuffle(shuffle_size,seed=10)\n",
        "\n",
        "  train_size=int(dataset_size*train_split)\n",
        "  val_size=int(validation_split*dataset_size)\n",
        "\n",
        "  train_ds=dataset.take(train_size)\n",
        "  val_ds=dataset.skip(train_size).take(val_size)\n",
        "  test_ds=dataset.skip(train_size).skip(val_size)\n",
        "\n",
        "  return train_ds, val_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHgvEnMX1wqw"
      },
      "outputs": [],
      "source": [
        "train_ds, val_ds, test_ds=train_test_split(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMXA3AmauLWD"
      },
      "source": [
        "- Check Class imbalance in train, valid and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0URi5T6Tzi_"
      },
      "source": [
        "# Optimize the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niuuj_EmT1yM"
      },
      "outputs": [],
      "source": [
        "train_ds=train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds=val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds=test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqtJ7TRzUe3i"
      },
      "source": [
        "# Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHnplREVUhBi"
      },
      "outputs": [],
      "source": [
        "resize_and_scale=tf.keras.Sequential([\n",
        "          layers.experimental.preprocessing.Resizing(IMG_SIZE,IMG_SIZE),\n",
        "          layers.experimental.preprocessing.Rescaling(1/255)\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFdlrcJVVZh-"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PWsaYOMVYV4"
      },
      "outputs": [],
      "source": [
        "train_dataset_gen =ImageDataGenerator(\n",
        "    preprocessing_function=resize_and_scale,\n",
        "    rotation_range=60,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=(0.0, 0.8)\n",
        ")\n",
        "\n",
        "train_generator = train_dataset_gen.flow_from_directory(\n",
        "        'dataset/train',\n",
        "        target_size=(IMG_SIZE,IMG_SIZE),\n",
        "        batch_size=32,\n",
        "        class_mode=\"sparse\",\n",
        "#         save_to_dir=\"C:\\\\Code\\\\potato-disease-classification\\\\training\\\\AugmentedImages\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = list(train_generator.class_indices.keys())\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_dataset_gen =ImageDataGenerator(\n",
        "    preprocessing_function=resize_and_scale,\n",
        "    rotation_range=60,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=(0.0, 0.8)\n",
        ")\n",
        "\n",
        "validation_generator = val_dataset_gen.flow_from_directory(\n",
        "        'dataset/val',\n",
        "        target_size=(IMG_SIZE,IMG_SIZE),\n",
        "        batch_size=32,\n",
        "        class_mode=\"sparse\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset_gen =ImageDataGenerator(\n",
        "    preprocessing_function=resize_and_scale,\n",
        "    rotation_range=60,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=(0.0, 0.8)\n",
        ")\n",
        "\n",
        "test_generator = test_dataset_gen.flow_from_directory(\n",
        "        'dataset/test',\n",
        "        target_size=(IMG_SIZE,IMG_SIZE),\n",
        "        batch_size=32,\n",
        "        class_mode=\"sparse\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHANNELS=3\n",
        "input_shape = (BATCH_SIZE, IMG_SIZE, IMG_SIZE, CHANNELS)\n",
        "\n",
        "classifier_model1 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/rishit-dagli/plant-disease/1\", input_shape=input_shape, trainable=True)\n",
        "])\n",
        "\n",
        "classifier_model2 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/agripredict/disease-classification/1\", input_shape=input_shape, trainable=True)\n",
        "])\n",
        "\n",
        "classifier_model3 = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/aiy/vision/classifier/plants_V1/1\", input_shape=input_shape, trainable=True)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_CLASSES=???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# change the model used here to classifier_model2 or classifier_model3 to use the other models\n",
        "\n",
        "model_used = classifier_model1\n",
        "\n",
        "model = models.Sequential([\n",
        "    model_used,\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "model.build(input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_ds, validation_data=val_ds, epochs=30, verbose=1, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = model.evaluate(test_ds)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
        "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
        "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "for image_batch, label_batch in test_generator:\n",
        "    first_image = image_batch[0]\n",
        "    first_label = int(label_batch[0])\n",
        "    \n",
        "    print(\"first image to predict\")\n",
        "    plt.imshow(first_image)\n",
        "    print(\"actual label:\",class_names[first_label])\n",
        "    \n",
        "    batch_prediction = model.predict(image_batch)\n",
        "    print(\"predicted label:\",class_names[np.argmax(batch_prediction[0])])\n",
        "    \n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"../model_name.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
