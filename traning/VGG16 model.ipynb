{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jrngLm6GijY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_hub as hub\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFb--39QYNI5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hwQQzeZMB76"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sabryqthLpfk"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=224\n",
        "BATCH_SIZE=32\n",
        "CHANNELS=3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE=224\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=10,\n",
        "        horizontal_flip=True,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        vertical_flip=False\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255)"
      ],
      "metadata": {
        "id": "E7eiVKUBCFFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory('/content/drive/MyDrive/Datasets/Cotton Disease/train',\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "OoRvOgSCCOOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g19qwk-3QqTf"
      },
      "outputs": [],
      "source": [
        "train_data.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_datagen.flow_from_directory('/content/drive/MyDrive/Datasets/Cotton Disease/test',\n",
        "                                                  target_size = (224,224),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "Q2jg55YZDAes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7t_xlb8Gizz"
      },
      "source": [
        "## VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Dense\n",
        "from glob import glob\n",
        "\n",
        "Image_size = [224,224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Datasets/Cotton Disease/train'\n",
        "test_path = '/content/drive/MyDrive/Datasets/Cotton Disease/test'"
      ],
      "metadata": {
        "id": "Xe_ObINbD4IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = VGG16(input_shape = Image_size + [3], weights = 'imagenet', include_top = False)"
      ],
      "metadata": {
        "id": "eLEatLM-ELnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.summary()"
      ],
      "metadata": {
        "id": "CVMLjwYtEQg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "a5sfK4y2EYf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_classes = glob(\"/content/drive/MyDrive/Datasets/Cotton Disease/train/*\")\n",
        "number_of_classes\n"
      ],
      "metadata": {
        "id": "sFQL5d2rEdPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "flatten_layer = Flatten()(vgg16.output)\n",
        "output_layer = Dense(len(number_of_classes),activation = 'softmax')(flatten_layer)"
      ],
      "metadata": {
        "id": "V1Jkmh8HE2dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "vgg16_model = Model(inputs = vgg16.input,outputs = output_layer)\n",
        "vgg16_model.summary()"
      ],
      "metadata": {
        "id": "vcQj7xkhFBgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.compile(loss= 'categorical_crossentropy',\n",
        "                   optimizer = 'adam',\n",
        "                   metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "6pnZ9kHtF6gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory('/content/drive/MyDrive/Datasets/Cotton Disease/train',\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'categorical')\n",
        "test_data = test_datagen.flow_from_directory('/content/drive/MyDrive/Datasets/Cotton Disease/test',\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "sqQYrAwOGSLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = vgg16_model.fit_generator(train_data,validation_data= test_data,epochs = 10,\n",
        "                                   steps_per_epoch=len(train_data),validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "X-BDw23iGsZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XWa78xuWQLlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "test_folder = \"/content/drive/MyDrive/Datasets/Cotton Disease/test\"  # Replace with the path to your test folder\n",
        "class_names = []\n",
        "\n",
        "for class_label in os.listdir(test_folder):\n",
        "    if os.path.isdir(os.path.join(test_folder, class_label)):\n",
        "        class_names.append(class_label)\n",
        "\n",
        "print(\"Found class_names:\", class_names)\n"
      ],
      "metadata": {
        "id": "HFWax1DTSLY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict Function"
      ],
      "metadata": {
        "id": "mDzSuQ7LkJaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = vgg16_model.evaluate(test_data)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "id": "xjZ4k5Qgkk19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Personal code for prediction. takes image path and predicts class and confidence\n",
        "\n",
        "# from keras.preprocessing import image\n",
        "# import numpy as np\n",
        "\n",
        "# img_path = \"/content/drive/MyDrive/Datasets/Cotton Disease/test/diseased cotton leaf/dis_leaf (260)_iaip.jpg\"  # Replace with the path to your image file\n",
        "# img = image.load_img(img_path, target_size=(224, 224))  # Adjust the target size to match your model's input size\n",
        "\n",
        "# def predict(model, img):\n",
        "#   img_array = image.img_to_array(img)\n",
        "\n",
        "#   img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "#   img_array = preprocess_input(img_array)\n",
        "\n",
        "#   predictions = vgg16_model.predict(img_array)\n",
        "#   confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "#   name = class_names[np.argmax(predictions)-1]\n",
        "\n",
        "#   return confidence, name"
      ],
      "metadata": {
        "id": "7wWb33OaS9jn"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def predict(model, img):\n",
        "  target_size = (224, 224)\n",
        "  width_ratio = target_size[0] / img.width\n",
        "  height_ratio = target_size[1] / img.height\n",
        "\n",
        "  # Resize the image\n",
        "  img = img.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "  # Convert the image to a numpy array\n",
        "  img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "\n",
        "  # Make predictions\n",
        "  predictions = model.predict(img_array)\n",
        "\n",
        "  # Get the label index with the highest confidence\n",
        "  confidence = round(100 * (np.max(predictions[0])), 2)\n",
        "  name = class_names[np.argmax(predictions)-1]\n",
        "\n",
        "  return confidence, name\n",
        "\n",
        "# Example usage:\n",
        "image_path = \"/content/drive/MyDrive/Datasets/Cotton Disease/test/diseased cotton leaf/dis_leaf (260)_iaip.jpg\"\n",
        "img = Image.open(image_path)\n",
        "\n",
        "confidence, label_index = predict(vgg16_model, img)\n",
        "print(f\"Predicted Label Name: {label_index}\")\n",
        "print(f\"Confidence: {confidence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boTsAcVcK3A0",
        "outputId": "7603c48b-c85c-474d-8bc5-b49d6e6ed7bc"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 43ms/step\n",
            "Predicted Label Name: diseased cotton leaf\n",
            "Confidence: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cN1t2IBhHJU"
      },
      "source": [
        "# Save Model-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "2j6x8Md5YGsM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "model_version=max([int(i) for i in os.listdir(\"/content/drive/MyDrive/Datasets/models/\") + [0]])+1\n",
        "vgg16_model.save(f\"/content/drive/MyDrive/Datasets/models/{model_version}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.save(\"/content/drive/MyDrive/Datasets/models/new_v2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuNpBatAvT43",
        "outputId": "fc7069a9-8638-4a27-b19e-20b74878c181"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}